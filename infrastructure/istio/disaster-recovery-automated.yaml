---
# Automated Disaster Recovery for HMS
apiVersion: batch/v1
kind: Job
metadata:
  name: hms-disaster-recovery
  namespace: ultimate-hms
spec:
  template:
    spec:
      serviceAccountName: dr-admin
      containers:
      - name: disaster-recovery
        image: hms/dr-controller:latest
        env:
        - name: PRIMARY_REGION
          value: "us-east-1"
        - name: DR_REGION
          value: "us-west-2"
        - name: RTO_TARGET
          value: "300"  # 5 minutes
        - name: RPO_TARGET
          value: "60"   # 1 minute
        - name: SLACK_WEBHOOK
          valueFrom:
            secretKeyRef:
              name: slack-webhook
              key: url
        command: ["/bin/sh", "-c"]
        args:
        - |
          # Health check function
          check_health() {
            local service=$1
            local max_attempts=30
            local attempt=1

            while [ $attempt -le $max_attempts ]; do
              if curl -f -s "http://$service/health" > /dev/null; then
                echo "âœ… $service is healthy"
                return 0
              fi
              echo "â³ Waiting for $service to be healthy (attempt $attempt/$max_attempts)"
              sleep 10
              ((attempt++))
            done

            echo "âŒ $service failed health check after $max_attempts attempts"
            return 1
          }

          # Primary region health check
          echo "ğŸ” Checking primary region health..."
          if check_health "api.hms.local"; then
            echo "âœ… Primary region is healthy, no action needed"
            exit 0
          fi

          echo "ğŸš¨ Primary region unhealthy, initiating failover..."

          # Update DNS to point to DR region
          aws route53 change-resource-record-sets \
            --hosted-zone-id $HOSTED_ZONE_ID \
            --change-batch '{
              "Changes": [{
                "Action": "UPSERT",
                "ResourceRecordSet": {
                  "Name": "api.hms.local",
                  "Type": "CNAME",
                  "TTL": 60,
                  "ResourceRecords": [{"Value": "'$DR_LOAD_BALANCER'"}]
                }
              }]
            }'

          # Scale up DR infrastructure
          kubectl --context=$DR_CONTEXT scale deployment hms-backend --replicas=10
          kubectl --context=$DR_CONTEXT scale deployment hms-frontend --replicas=5

          # Wait for DR services to be ready
          echo "â³ Waiting for DR services to scale up..."
          sleep 120

          # Health check DR region
          if check_health "$DR_LOAD_BALANCER"; then
            echo "âœ… DR region is healthy, failover complete"

            # Send notification
            curl -X POST $SLACK_WEBHOOK \
              -H 'Content-type: application/json' \
              -d '{"text":"ğŸš¨ HMS Failover Completed - Traffic switched to DR region"}'

            # Start backup restoration if needed
            echo "ğŸ“¦ Starting backup restoration..."
            ./restore-from-backup.sh latest

          else
            echo "âŒ DR region failed health check, manual intervention required"

            # Send critical alert
            curl -X POST $SLACK_WEBHOOK \
              -H 'Content-type: application/json' \
              -d '{"text":"ğŸš¨ CRITICAL: HMS DR Failover Failed - Manual intervention required"}'
          fi
      restartPolicy: OnFailure

---
# Backup Automation
apiVersion: batch/v1
kind: CronJob
metadata:
  name: hms-automated-backup
  namespace: ultimate-hms
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-admin
          containers:
          - name: database-backup
            image: hms/backup-tool:latest
            env:
            - name: BACKUP_TYPE
              value: "incremental"
            - name: RETENTION_DAYS
              value: "30"
            - name: S3_BUCKET
              value: "hms-backups-prod"
            command: ["/bin/sh", "-c"]
            args:
            - |
              # Database backup
              echo "ğŸ“¦ Creating database backup..."
              pg_dump -h postgresql -U hms_user -d hms_db \
                --format=custom --compress=9 --no-password \
                > /tmp/hms_backup_$(date +%Y%m%d_%H%M%S).dump

              # Upload to S3
              aws s3 cp /tmp/hms_backup_*.dump s3://$S3_BUCKET/database/

              # Application state backup
              echo "ğŸ’¾ Backing up application state..."
              kubectl get all -o yaml > /tmp/k8s-state-$(date +%Y%m%d_%H%M%S).yaml
              aws s3 cp /tmp/k8s-state-*.yaml s3://$S3_BUCKET/k8s-state/

              # Clean up old backups
              echo "ğŸ§¹ Cleaning up old backups..."
              aws s3 ls s3://$S3_BUCKET/database/ | while read -r line; do
                createDate=`echo $line | awk {'print $1" "$2'}`
                createDate=`date -d"$createDate" +%s`
                olderThan=`date -d"30 days ago" +%s`
                if [[ $createDate -lt $olderThan ]]; then
                  fileName=`echo $line | awk {'print $4'}`
                  if [[ $fileName != "" ]]; then
                    aws s3 rm s3://$S3_BUCKET/database/$fileName
                  fi
                fi
              done

              echo "âœ… Backup completed successfully"
          volumeMounts:
          - name: backup-storage
            mountPath: /tmp
          restartPolicy: OnFailure
      volumes:
      - name: backup-storage
        emptyDir: {}

---
# Backup Restoration Script
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-restore-scripts
  namespace: ultimate-hms
data:
  restore-from-backup.sh: |
    #!/bin/bash
    set -e

    BACKUP_NAME=$1
    if [ -z "$BACKUP_NAME" ]; then
      echo "Usage: $0 <backup-name>"
      echo "Available backups:"
      aws s3 ls s3://hms-backups-prod/database/
      exit 1
    fi

    echo "ğŸ“¥ Downloading backup: $BACKUP_NAME"
    aws s3 cp s3://hms-backups-prod/database/$BACKUP_NAME /tmp/backup.dump

    echo "ğŸ›‘ Stopping application services..."
    kubectl scale deployment hms-backend --replicas=0
    kubectl scale deployment hms-frontend --replicas=0

    echo "ğŸ”„ Restoring database..."
    pg_restore -h postgresql -U hms_user -d hms_db \
      --clean --if-exists --no-password /tmp/backup.dump

    echo "ğŸš€ Starting application services..."
    kubectl scale deployment hms-backend --replicas=3
    kubectl scale deployment hms-frontend --replicas=2

    echo "â³ Waiting for services to be ready..."
    sleep 120

    echo "ğŸ” Running health checks..."
    if curl -f http://hms-backend/health; then
      echo "âœ… Restoration completed successfully"
    else
      echo "âŒ Health check failed, manual intervention required"
      exit 1
    fi

  validate-backup.sh: |
    #!/bin/bash
    set -e

    BACKUP_FILE=$1
    if [ -z "$BACKUP_FILE" ]; then
      echo "Usage: $0 <backup-file>"
      exit 1
    fi

    echo "ğŸ” Validating backup integrity..."

    # Check file exists and is readable
    if [ ! -f "$BACKUP_FILE" ]; then
      echo "âŒ Backup file not found: $BACKUP_FILE"
      exit 1
    fi

    # Check file size
    FILE_SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
    if [ "$FILE_SIZE" -lt 1000000 ]; then  # Less than 1MB
      echo "âš ï¸  Backup file seems too small: $FILE_SIZE bytes"
    fi

    # Try to list contents (for custom format)
    if pg_restore -l "$BACKUP_FILE" > /dev/null 2>&1; then
      echo "âœ… Backup file format is valid"
      ITEM_COUNT=$(pg_restore -l "$BACKUP_FILE" | wc -l)
      echo "ğŸ“Š Backup contains $ITEM_COUNT items"
    else
      echo "âŒ Invalid backup file format"
      exit 1
    fi

    echo "âœ… Backup validation completed successfully"

---
# DR Monitoring and Alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: hms-dr-alerts
  namespace: ultimate-hms
spec:
  groups:
  - name: hms.dr
    rules:
    - alert: HMSDRFailoverTriggered
      expr: up{job="hms-backend"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "HMS Primary Region Down - DR Failover Triggered"
        description: "HMS backend has been down for 5 minutes. DR failover should be initiated."

    - alert: HMSDRFailoverCompleted
      expr: up{job="hms-backend-dr"} == 1
      for: 1m
      labels:
        severity: info
      annotations:
        summary: "HMS DR Failover Completed"
        description: "Traffic has been successfully switched to DR region."

    - alert: HMSBackupFailed
      expr: rate(backup_failures_total[5m]) > 0
      labels:
        severity: warning
      annotations:
        summary: "HMS Backup Failed"
        description: "Automated backup process has failed. Manual backup required."