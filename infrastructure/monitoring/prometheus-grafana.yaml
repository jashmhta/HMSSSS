---
# Ultimate HMS - Prometheus + Grafana Monitoring Stack
# This configuration sets up comprehensive monitoring and alerting

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: hms-cluster

    rule_files:
      - /etc/prometheus/alert_rules.yml

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'hms-services'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: hospital-management-system
          - source_labels: [__meta_kubernetes_pod_label_component]
            action: keep
            regex: .+
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            action: keep
            regex: 9090|8080|9200|27017|5432
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod_name

  alert_rules.yml: |
    groups:
      - name: hms-alerts
        rules:
          - alert: HighPodRestartRate
            expr: rate(kube_pod_container_status_restarts_total{namespace="ultimate-hms"}[5m]) > 0.1
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "High pod restart rate in namespace {{ $labels.namespace }}"
              description: "Pod {{ $labels.pod }} is restarting frequently"

          - alert: HighMemoryUsage
            expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage on node {{ $labels.instance }}"
              description: "Memory usage is {{ $value }}%"

          - alert: HighCPUUsage
            expr: (1 - rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100 > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage on node {{ $labels.instance }}"
              description: "CPU usage is {{ $value }}%"

          - alert: DatabaseConnectionIssues
            expr: up{job="hms-services", component="database"} == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Database connection issues"
              description: "Database {{ $labels.system }} is down"

          - alert: ServiceDown
            expr: up{job="hms-services"} == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Service is down"
              description: "Service {{ $labels.system }} in namespace {{ $labels.namespace }} is down"

          - alert: HighErrorRate
            expr: rate(http_requests_total{status=~"5..", namespace="ultimate-hms"}[5m]) / rate(http_requests_total{namespace="ultimate-hms"}[5m]) * 100 > 5
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value }}% for service {{ $labels.service }}"

          - alert: DiskSpaceLow
            expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 15
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Low disk space on node {{ $labels.instance }}"
              description: "Disk space is {{ $value }}% available"

---
# Prometheus StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: prometheus
spec:
  serviceName: prometheus
  replicas: 1
  selector:
    matchLabels:
      app: hospital-management-system
      component: monitoring
      system: prometheus
  template:
    metadata:
      labels:
        app: hospital-management-system
        component: monitoring
        system: prometheus
    spec:
      serviceAccountName: hms-admin
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        ports:
        - containerPort: 9090
          name: http
        args:
        - --config.file=/etc/prometheus/prometheus.yml
        - --storage.tsdb.path=/prometheus
        - --web.console.libraries=/etc/prometheus/console_libraries
        - --web.console.templates=/etc/prometheus/consoles
        - --storage.tsdb.retention.time=200h
        - --web.enable-lifecycle
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus/prometheus.yml
          subPath: prometheus.yml
        - name: alert-rules
          mountPath: /etc/prometheus/alert_rules.yml
          subPath: alert_rules.yml
        - name: prometheus-data
          mountPath: /prometheus
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 1000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
          items:
          - key: prometheus.yml
            path: prometheus.yml
      - name: alert-rules
        configMap:
          name: prometheus-config
          items:
          - key: alert_rules.yml
            path: alert_rules.yml
  volumeClaimTemplates:
  - metadata:
      name: prometheus-data
      labels:
        app: hospital-management-system
        component: monitoring
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi
      storageClassName: standard

---
# Prometheus Service
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: prometheus
spec:
  selector:
    app: hospital-management-system
    component: monitoring
    system: prometheus
  ports:
  - name: http
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# Alertmanager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: alertmanager
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hospital-management-system
      component: monitoring
      system: alertmanager
  template:
    metadata:
      labels:
        app: hospital-management-system
        component: monitoring
        system: alertmanager
    spec:
      serviceAccountName: hms-admin
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        ports:
        - containerPort: 9093
          name: http
        args:
        - --config.file=/etc/alertmanager/alertmanager.yml
        - --storage.path=/alertmanager
        volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager/alertmanager.yml
          subPath: alertmanager.yml
        - name: alertmanager-data
          mountPath: /alertmanager
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 200m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: alertmanager-config
        configMap:
          name: alertmanager-config
      - name: alertmanager-data
        emptyDir: {}

---
# Alertmanager ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@hms.local'
      smtp_auth_username: 'alerts@hms.local'
      smtp_auth_password: 'alert_password'

    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'hms-team'
      routes:
      - match:
          severity: critical
        receiver: 'hms-critical'

    receivers:
    - name: 'hms-team'
      email_configs:
      - to: 'team@hms.local'
        send_resolved: true
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#hms-alerts'
        send_resolved: true

    - name: 'hms-critical'
      email_configs:
      - to: 'critical@hms.local'
        send_resolved: true
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
        send_resolved: true

---
# Alertmanager Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: alertmanager
spec:
  selector:
    app: hospital-management-system
    component: monitoring
    system: alertmanager
  ports:
  - name: http
    port: 9093
    targetPort: 9093
  type: ClusterIP

---
# Grafana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hospital-management-system
      component: monitoring
      system: grafana
  template:
    metadata:
      labels:
        app: hospital-management-system
        component: monitoring
        system: grafana
    spec:
      serviceAccountName: hms-admin
      containers:
      - name: grafana
        image: grafana/grafana:10.1.0
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: "admin"
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        - name: GF_USERS_ALLOW_SIGN_UP
          value: "false"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel,grafana-worldmap-panel"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana/provisioning
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: grafana-storage
        emptyDir: {}
      - name: grafana-config
        configMap:
          name: grafana-config

---
# Grafana ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
data:
  datasources.yml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true

  dashboards.yml: |
    apiVersion: 1
    providers:
    - name: 'HMS Dashboards'
      type: file
      disableDeletion: false
      updateIntervalSeconds: 10
      allowUiUpdates: true
      options:
        path: /var/lib/grafana/dashboards

---
# Grafana Secret
apiVersion: v1
kind: Secret
metadata:
  name: grafana-secret
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
type: Opaque
data:
  admin-password: Z3JhZmFuYV9hZG1pbl9wYXNzd29yZA==  # base64 encoded: grafana_admin_password

---
# Grafana Service
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: grafana
spec:
  selector:
    app: hospital-management-system
    component: monitoring
    system: grafana
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  type: ClusterIP

---
# Grafana Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - grafana.hms.local
    secretName: grafana-tls
  rules:
  - host: grafana.hms.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000

---
# Node Exporter DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: node-exporter
spec:
  selector:
    matchLabels:
      app: hospital-management-system
      component: monitoring
      system: node-exporter
  template:
    metadata:
      labels:
        app: hospital-management-system
        component: monitoring
        system: node-exporter
    spec:
      serviceAccountName: hms-admin
      containers:
      - name: node-exporter
        image: prom/node-exporter:v1.6.1
        ports:
        - containerPort: 9100
          name: metrics
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        - name: rootfs
          mountPath: /host/rootfs
          readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: rootfs
        hostPath:
          path: /

---
# Node Exporter Service
apiVersion: v1
kind: Service
metadata:
  name: node-exporter
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
    system: node-exporter
spec:
  selector:
    app: hospital-management-system
    component: monitoring
    system: node-exporter
  ports:
  - name: metrics
    port: 9100
    targetPort: 9100
  type: ClusterIP

---
# Monitoring ServiceMonitor (for Prometheus)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: monitoring-servicemonitor
  namespace: ultimate-hms
  labels:
    app: hospital-management-system
    component: monitoring
spec:
  selector:
    matchLabels:
      app: hospital-management-system
      component: monitoring
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    relabelings:
    - sourceLabels: [__meta_kubernetes_service_label_system]
      regex: "prometheus"
      action: keep
    - targetLabel: service
      replacement: prometheus